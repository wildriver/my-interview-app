# AI Voice Interviewer (Powered by Groq)

ブラウザだけで動作する、超高速AI音声インタビューアプリです。
Groq APIの圧倒的な推論速度と、ブラウザ標準のWeb Speech APIを組み合わせることで、リアルタイムに近い自然な音声会話を実現しています。

## 特徴

- **完全音声対話**: マイクに向かって話すだけで、AIインタビュアーが音声で応答します。
- **爆速レスポンス**: 推論エンジンに [Groq](https://groq.com/) を採用。待ち時間のない会話が可能です。
- **プライバシー重視**: サーバーサイドのデータベースは不要。会話ログはすべてあなたのブラウザ内 (`IndexedDB`) に保存されます。
- **Bring Your Own Key**: ユーザー自身のGroq API Keyを使用するため、開発者にキーを渡す必要がなく安全です。
- **自動サマリー生成**: インタビュー終了後、AIが会話内容を要約し、フィードバックとして保存します。
- **5種類のAI性格**: 傾聴型、盛り上げ型、深掘り型、チェック型、要約型から選択可能。
- **動的なインタビュー進行**: 回答の質に応じて深掘りしたり、次のトピックに移行したりと、人間らしい柔軟な進行を実現。

## デモ

**[デモアプリを開く](https://yutaka-arakawa.github.io/my-interview-ai/)**

> **注意**: ブラウザの音声認識機能 (`webkitSpeechRecognition`) を使用するため、**Google Chrome** でアクセスしてください。

## 使い方

### 1. Groq APIキーの取得
[Groq Cloud Console](https://console.groq.com/keys) にアクセスし、API Key（無料枠あり）を取得します。
APIキーはサーバには保存されません。ブラウザのlocalStorageに保存するオプションがあります。

### 2. アプリ設定
- APIキーを入力
- AIのモデルを選択（推奨: Llama 3.1 8B Instant）
- AIの性格を5種類から選択
- インタビューのタイトル、事前知識、聞きたいことリストを設定
- 音声と速度を調整

### 3. インタビュー開始
「開始する」ボタンを押し、マイクの使用を許可してください。
AIが質問を投げかけ、回答が終わると自動検知でAIが返答します。

## AI性格タイプ

| タイプ | 特徴 |
|--------|------|
| 傾聴型 | 本音を引き出すカウンセラー風。感情や価値観を重視 |
| 盛り上げ型 | ポジティブMC風。楽しくエピソードを引き出す |
| 深掘り型 | 冷静に分析・仮説検証。定義や根拠を明確化 |
| チェック型 | やや批判的に検証。矛盾や弱点を指摘 |
| 要約型 | まとめ役。構造化して言質を確認 |

## モデル選択とレート制限

Groq APIには無料枠があり、モデルによってレート制限が異なります。

| モデル | RPD (リクエスト/日) | TPD (トークン/日) | 特徴 |
|--------|---------------------|-------------------|------|
| **Llama 3.1 8B Instant** | 14,400 | 500,000 | **推奨**: 高速・高制限 |
| Llama 3.3 70B | 1,000 | 100,000 | 高品質だが制限厳しめ |
| その他 | モデルにより異なる | - | [公式ドキュメント参照](https://console.groq.com/docs/rate-limits) |

### 利用量の目安
- インタビュー1回あたり: 10〜30リクエスト、20,000〜50,000トークン
- **Llama 3.1 8Bなら1日10〜20回のインタビューが可能**

## 技術構成

```
┌─────────────────────────────────────────────────────┐
│                    ブラウザ                          │
│  ┌──────────────┐  ┌──────────────┐  ┌───────────┐ │
│  │ Web Speech   │  │ IndexedDB    │  │ localStorage│ │
│  │ API (STT/TTS)│  │ (履歴保存)    │  │ (設定保存)  │ │
│  └──────────────┘  └──────────────┘  └───────────┘ │
│         │                                           │
│         ▼                                           │
│  ┌──────────────────────────────────────────────┐  │
│  │              interview_app.html               │  │
│  │  - 音声認識・合成制御                          │  │
│  │  - 会話履歴管理                               │  │
│  │  - 動的プロンプト生成                          │  │
│  └──────────────────────────────────────────────┘  │
│                        │                            │
└────────────────────────│────────────────────────────┘
                         │ HTTPS (fetch)
                         ▼
              ┌─────────────────────┐
              │     Groq API        │
              │  (LLM推論エンジン)   │
              └─────────────────────┘
```

### 主な技術
- **フロントエンド**: Vanilla JavaScript（フレームワーク不使用）
- **音声認識**: Web Speech API (`webkitSpeechRecognition`)
- **音声合成**: Web Speech API (`SpeechSynthesis`)
- **LLM**: Groq API（Llama 3.1 8B / 3.3 70B など）
- **データ保存**: IndexedDB（履歴）、localStorage（設定）

## デプロイ

### GitHub Pages（推奨）
Web Speech APIはHTTPS環境が必要です。GitHub Pagesで簡単にホスティングできます。

```bash
# リポジトリをGitHubにプッシュ
git push origin main

# Settings > Pages > Source: main branch
```

### ローカル実行
```bash
# 任意のHTTPサーバーで起動
npx serve .
# または
python -m http.server 8000
```

> **注意**: Vercelでは音声認識が動作しない場合があります（Web Speech APIの制限）。GitHub Pagesを推奨します。

## ファイル構成

```
my-interview-app/
├── index.html          # 設定画面
├── interview_app.html  # インタビュー実行画面
├── README.md
└── vercel.json         # (参考用)
```

## ライセンス

MIT License
