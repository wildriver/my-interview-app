# AI Voice Interviewer (Powered by Groq)

ブラウザだけで動作する、超高速AI音声インタビューアプリです。
Groq APIの圧倒的な推論速度と、音声認識（Groq Whisper / Web Speech API）を組み合わせることで、リアルタイムに近い自然な音声会話を実現しています。

> **[English version (README_EN.md)](README_EN.md)**

## 特徴

- **完全音声対話**: マイクに向かって話すだけで、AIインタビュアーが音声で応答します。
- **爆速レスポンス**: 推論エンジンに [Groq](https://groq.com/) を採用。待ち時間のない会話が可能です。
- **多言語対応**: 日本語・英語・ドイツ語のUIに対応。言語切替はワンクリック。
- **2種類の音声認識**: Groq Whisper（高精度）とWeb Speech API（無料・ブラウザ内蔵）から選択可能。
- **プライバシー重視**: サーバーサイドのデータベースは不要。会話ログはすべてブラウザ内（`IndexedDB`）に保存。
- **Bring Your Own Key**: ユーザー自身のGroq API Keyを使用するため安全です。
- **自動サマリー生成**: インタビュー終了後、AIが会話内容を要約し保存します。
- **5種類のAI性格**: インタビューの目的に合わせて最適な性格を選択可能。
- **動的なインタビュー進行**: 回答の質に応じて深掘りしたり、次のトピックに移行したりと、柔軟な進行を実現。
- **テキスト入力対応**: 音声が使えない環境でもテキスト入力でインタビュー可能。

## デモ

**[デモアプリを開く](https://wildriver.github.io/my-interview-app/index.html)**

> **推奨ブラウザ**: Google Chrome / Microsoft Edge（音声認識機能のため）

## 使い方

### 1. Groq APIキーの取得
[Groq Cloud Console](https://console.groq.com/keys) にアクセスし、API Key（無料枠あり）を取得します。
APIキーはサーバには送信されません。ブラウザの`localStorage`に保存するオプションがあります。

### 2. アプリ設定
- APIキーを入力（残量チェック機能付き）
- AIのモデルを選択（8種類から選択可能）
- AIの性格を5種類から選択
- 音声認識エンジンを選択（Groq Whisper / Web Speech API）
- インタビューのタイトル、事前知識、聞きたいことリストを設定
- 音声と速度を調整
- UIの言語を切替（日本語 / English / Deutsch）

### 3. インタビュー開始
「開始する」ボタンを押し、マイクの使用を許可してください。
AIが質問を投げかけ、回答が終わると自動でAIが返答します。

## AI性格タイプ

| タイプ | 特徴 |
|--------|------|
| 🎧 傾聴型 | 本音を引き出すカウンセラー風。感情や価値観を重視 |
| 🎤 盛り上げ型 | ポジティブMC風。楽しくエピソードを引き出す |
| 🔍 深掘り型 | 冷静に分析・仮説検証。定義や根拠を明確化 |
| 📝 チェック型 | やや批判的に検証。矛盾や弱点を指摘 |
| 📋 要約型 | まとめ役。構造化して言質を確認 |

## モデル選択

Groq APIには無料枠があり、モデルによってレート制限が異なります。
アプリ内の「残量チェック」ボタンで各モデルの残りリクエスト数を確認できます。

| モデル | タグ | 特徴 |
|--------|------|------|
| **Llama 3.1 8B Instant** | 最速 | **推奨**: 高速・高い無料枠 |
| GPT-OSS 20B | 高速 | OpenAI互換の高速モデル |
| Llama 4 Maverick 17B | 高速 | Meta最新のMoEモデル |
| Llama 4 Scout 17B | - | 軽量なScoutバリアント |
| Qwen3 32B | - | Alibaba製の高性能モデル |
| Llama 3.3 70B | 高品質 | 高品質だが制限厳しめ |
| GPT-OSS 120B | 高品質 | 大規模・高品質 |
| Kimi K2 Instruct | - | Moonshot AI製モデル |

### 利用量の目安
- インタビュー1回あたり: 10〜30リクエスト、20,000〜50,000トークン
- Llama 3.1 8Bなら1日10〜20回のインタビューが可能

## 音声認識エンジン

| エンジン | 精度 | コスト | 備考 |
|----------|------|--------|------|
| **Groq Whisper** | 高精度 | APIクレジット消費 | 推奨。安定した認識精度 |
| Web Speech API | 中程度 | 無料 | Chrome/Edge必須。ネットワーク接続が必要 |

## 技術構成

```
┌──────────────────────────────────────────────────────┐
│                     ブラウザ                           │
│  ┌──────────────┐  ┌──────────────┐  ┌────────────┐  │
│  │ Speech API   │  │ IndexedDB    │  │ localStorage│  │
│  │ (TTS)        │  │ (履歴保存)    │  │ (設定保存)  │  │
│  └──────────────┘  └──────────────┘  └────────────┘  │
│         │                                             │
│         ▼                                             │
│  ┌────────────────────────────────────────────────┐   │
│  │             interview_app.html                  │   │
│  │  - 音声認識・合成制御                            │   │
│  │  - 会話履歴管理                                 │   │
│  │  - 動的プロンプト生成                            │   │
│  │  - i18n多言語サポート                            │   │
│  └────────────────────────────────────────────────┘   │
│                        │                              │
└────────────────────────│──────────────────────────────┘
                         │ HTTPS (fetch)
                         ▼
              ┌───────────────────────┐
              │      Groq API         │
              │  LLM推論 + Whisper STT │
              └───────────────────────┘
```

### 主な技術
- **フロントエンド**: Vanilla JavaScript（フレームワーク不使用）
- **音声認識**: Groq Whisper API / Web Speech API
- **音声合成**: Web Speech API (`SpeechSynthesis`)
- **LLM**: Groq API（Llama 3.1 8B / 3.3 70B / Llama 4 など）
- **多言語対応**: 独自i18nエンジン（`i18n.js` + 言語ファイル）
- **データ保存**: IndexedDB（履歴）、localStorage（設定・言語選択）

## ファイル構成

```
my-interview-app/
├── index.html           # 設定画面（3カラムレイアウト）
├── interview_app.html   # インタビュー実行画面
├── i18n.js              # 多言語対応コアエンジン
├── lang/
│   ├── ja.js            # 日本語
│   ├── en.js            # English
│   └── de.js            # Deutsch
├── README.md            # このファイル（日本語）
├── README_EN.md         # English README
├── ogp.png              # OGP画像
└── screenshot.jpg       # スクリーンショット
```

## デプロイ

### GitHub Pages（推奨）
音声認識にはHTTPS環境が必要です。GitHub Pagesで簡単にホスティングできます。

```bash
# リポジトリをGitHubにプッシュ
git push origin main

# Settings > Pages > Source: main branch
```

### ローカル実行
```bash
# 任意のHTTPサーバーで起動
npx serve .
# または
python -m http.server 8000
```

> **注意**: Vercelでは音声認識が動作しない場合があります（Web Speech APIの制限）。GitHub Pagesを推奨します。

## ライセンス

Apache License 2.0
